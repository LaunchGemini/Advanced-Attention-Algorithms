
# Advanced-Attention-Algorithms\nThis project provides implementations of various attention mechanisms in PyTorch.\n\n***\n# Attention Series\n\n- Pytorch implementation of ["Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks---arXiv 2021.05.05"](https://arxiv.org/abs/2105.02358)\n\n<truncated to match character limit>...\n\n# Special Note\nRepo owner is LaunchGemini.